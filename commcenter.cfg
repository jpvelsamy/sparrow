[common]
private-key-path=/home/deploy/.ssh/id_rsa
java-home=/home/deploy/jdk1.8.0_40
maven-repo=.m2/repository

[release]
version-universal=1.0.0

[build]
checkout-dir=/home/deploy/checkout_master
should-skip-unit-test=true
environment=prod

[nrtp-cluster]
nrt-project-name=crawler
#please do not add space in between the machine names, currently I feeling lazy to perform space stripping, will get it done later
worker-machine-list=crawl-node-001,crawl-node-002,crawl-node-003,crawl-node-004
#worker-machine-list=crawl-node-001
manager-machine=cluster-001
destination-folder=/home/deploy/autodeploy/humingo-nrt
#repeating configuration always leads to issues, please remove redundancy
command-dir=/home/deploy/autodeploy/humingo-nrt/humingo-crawler/bin
compressed-file-name=humingo-crawler-dist.tar.gz
user=deploy
scheduler-admin-port=18066
scheduler-app-port=
job-manager-port=
frontier-port=2553
jars-to-delete=netty-3.2.4.Final.jar
frontier-instances=3
seed-jmx-port=6022

[web-app]
web-project-name=product-search-web
machine-list=cluster-web-001,cluster-web-002
destination-folder=/home/deploy/cleanbuild/autodeploy
tomcat-dir=/opt/tomcat
command-dir=/home/deploy/bin
compressed-file-name=humingo.war
archive-folder=/data/backup/software/product-web
user=deploy
admin-port=36132

[batch-curation]
batch-project-name=batch
compressed-file-name=humingo-batch-bundle.tar.gz
machine-list=cluster-001,cluster-003,cluster-web-001
destination-folder=/home/deploy/autodeploy/batch
archive-folder=/data/backup/software/batch
user=deploy
python=python2.7
module=hadoop.py
#these two commands are important and their spelling should be correct to the the T
curate-command=curate
parse-command=parse
curation-machine=cluster-001
command-dir=/home/deploy/autodeploy/batch/humingo-batch/bin
3pp-lib=org/apache/httpcomponents/httpmime/4.3.1/httpmime-4.3.1.jar,org/apache/httpcomponents/httpclient/4.3.1/httpclient-4.3.1.jar,org/slf4j/slf4j-log4j12/1.7.OA5/slf4j-log4j12-1.7.5.jar,org/slf4j/slf4j-api/1.7.5/slf4j-api-1.7.5.jar,com/fasterxml/jackson/dataformat/jackson-dataformat-csv/2.4.0/jackson-dataformat-csv-2.4.0.jar,org/apache/httpcomponents/httpcore/4.3.2/httpcore-4.3.2.jar
jars-to-remove=slf4j-log4j12-1.6.1.jar
jdbc-url=jdbc:mysql://cluster-001:3306/humingo_config?dumpQueriesOnException
jdbc-user=humingo
jdbc-passwd=humingo
crawl-table=v2_crawl
column-family=crawl_content
parsed-product-table=parsed_product
classified-product-table=classified_product
store-version=v2_
curationstatussql=select if(count(*)>0,'True','False') as count_status from curation_audit;select if(status='started','True','False') as curation_stats from curation_audit where status not in ('failure-crawl-lock','failure-curation-lock','failure-index-lock')order by curation_audit_id desc limit 1;

[export]
command-dir=/home/deploy/autodeploy/batch/humingo-batch/bin
command-file=exportbreadcrumb.sh
table-version=v2_
export-folder=/home/deploy/export
export-delata=false

[crawl]
target-machine-url=http://cluster-001.humingo.com:18066/job
start-command=start
crawlstatussql=select if(count(*)>0,'True','False') as count_status from crawl_audit;select if(status='started','True','False') as crawl_status from crawl_audit where status not in ('failure-crawl-lock','failure-curation-lock','failure-index-lock') order by crawl_audit_id desc limit 1;
user=deploy
waittime-to-cleanup=10
#popular products crawling
hippo-job-name=hippo

[humingo-job]
host=cluster-001
port=3306
database=humingo_jobs
user=humingo
passwd=humingo
#fullstocksql=select job_name from humingo_config.job_config where crawl_type='ADAPTIVE_FULL';
fullstocksql=SELECT a.job_name FROM humingo_config.job_config a WHERE a.crawl_type='ADAPTIVE_FULL' AND a.job_name NOT IN(SELECT DISTINCT b.job_name from crawl_audit_detail b INNER JOIN crawl_audit c ON b.crawl_audit_id=c.crawl_audit_id WHERE date(c.crawl_end_time)<=curdate() and date(c.crawl_end_time)>date_sub(now(), interval 1 day)) LIMIT 3;
#;select job_name from humingo_config.job_config where crawl_type='ADAPTIVE_FULL' LIMIT 1
channelsql=select a.channel_name from curation_channel_list a inner join crawl_audit_detail b on a.channel_name = substring_index(b.job_name,'-',1) inner join crawl_audit c on b.crawl_audit_id=c.crawl_audit_id WHERE date(c.crawl_end_time)<=curdate() and date(c.crawl_end_time)>date_sub(now(), interval 2 day);
parsecandidatesql=select channel_name from new_channel_list where is_active=1;

[index]
command-dir=/home/deploy/autodeploy/batch/humingo-batch/index-config
index-machine=cluster-003
user=deploy
indexstatussql=select if(count(*)>0,'True','False') as count_status from index_audit;select if(status='started','True','False') as index_status from index_audit order by index_audit_id desc limit 1
index-host-machine=cluster-web-001,cluster-web-002
index-swap-command=/home/deploy/bin/swapindex.sh
index-config-file-path=/home/deploy/humingo.conf.backup
primary-indexsql=SELECT index_name FROM index_name_master WHERE index_type='primary'
secondary-indexsql=SELECT  index_name FROM index_name_master WHERE index_type='secondary'